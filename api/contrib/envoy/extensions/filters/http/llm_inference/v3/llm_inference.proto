syntax = "proto3";

package envoy.extensions.filters.http.llm_inference.v3;

import "udpa/annotations/status.proto";
import "validate/validate.proto";

option java_package = "io.envoyproxy.envoy.extensions.filters.http.llm_inference.v3";
option java_outer_classname = "LlmInferenceProto";
option java_multiple_files = true;
option (udpa.annotations.file_status).package_version_status = ACTIVE;

message modelParameter {
  int32 n_threads = 1;
  int32 n_parallel = 2;
  bool embedding = 3;
  map<string, string> modelpath = 4;
}

message modelChosen {
  string usemodel = 1;
}
