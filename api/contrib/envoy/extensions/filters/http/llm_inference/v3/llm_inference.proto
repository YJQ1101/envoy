syntax = "proto3";

package envoy.extensions.filters.http.llm_inference.v3;

import "udpa/annotations/status.proto";
import "validate/validate.proto";

option java_package = "io.envoyproxy.envoy.extensions.filters.http.llm_inference.v3";
option java_outer_classname = "LlmInferenceProto";
option java_multiple_files = true;
option (udpa.annotations.file_status).package_version_status = ACTIVE;

message modelParameter {
  int32 n_thread = 1;

  map<string, string> modelpath = 2;
}

message modelChosen {
  repeated string usemodel = 1;
}
